{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describing a Lab Protocol from Video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image as PyImage\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import time\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def resize(img, size=512):\n",
    "    original_width, original_height = img.size\n",
    "    aspect_ratio = original_width / original_height\n",
    "\n",
    "    if original_width < original_height:\n",
    "        new_width = size\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "    else:\n",
    "        new_height = size\n",
    "        new_width = int(new_height * aspect_ratio)\n",
    "\n",
    "    return img.resize((new_width, new_height), Image.BICUBIC)\n",
    "\n",
    "def extract_data(filename, frameskip=10):\n",
    "    video = VideoFileClip(filename)\n",
    "\n",
    "    # Extract frames\n",
    "    frames = []\n",
    "    for i, frame in enumerate(video.iter_frames()):\n",
    "        if i % frameskip == 0:\n",
    "            frame_image = Image.fromarray(frame).resize((512,512), Image.BICUBIC)\n",
    "            im_file = BytesIO()\n",
    "            frame_image.save(im_file, format=\"JPEG\")\n",
    "            im_bytes = im_file.getvalue()\n",
    "            frames.append(base64.b64encode(im_bytes).decode('utf-8'))\n",
    "\n",
    "    # Extract audio\n",
    "    audio = video.audio\n",
    "    audio_file = \"extracted_audio.mp3\"\n",
    "    audio.write_audiofile(audio_file)\n",
    "\n",
    "    return frames, audio_file\n",
    "\n",
    "def transcribe(audio_filepath):\n",
    "    transcript = client.audio.transcriptions.create(\n",
    "        file=open(audio_filepath, \"rb\"),\n",
    "        model=\"whisper-1\",\n",
    "        # prompt=prompt,\n",
    "    )\n",
    "    return transcript.text\n",
    "\n",
    "def approx_cost(frames, transcript, token_output=300):\n",
    "    image_cost = 0.00765 * len(frames)\n",
    "    transcript_cost = 0.01 / 1000 * len(transcript.split()) * 1.4\n",
    "    output_cost = token_output * 0.03 / 1000\n",
    "    return f\"Images: {image_cost}\\nTranscript: {transcript_cost}\\nOutput: {output_cost}\\nTotal: {image_cost + transcript_cost + output_cost}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display frames to make sure we've read them in correctly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in extracted_audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "N frames: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Load your video\n",
    "video_file = \"dynamic-video.mp4\"\n",
    "frames, audiofile = extract_data(video_file, frameskip=60)\n",
    "print(f\"N frames: {len(frames)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_handle = display(None, display_id=True)\n",
    "for img in frames:\n",
    "    display_handle.update(PyImage(data=base64.b64decode(img.encode(\"utf-8\"))))\n",
    "    time.sleep(0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm picking up a pipette, taking a tip, aspirating 25 microliters from A1 and dispensing it into A9. I am threshing my tip and switching pipette. I am going to take a new tip, aspirate 1 microliter from well A3 and dispensing it into well A9. I am threshing the tip, I am picking up a new tip, I am going to aspirate 1 microliter from well A5 and dispensing it into well A9. I am threshing the tip and I'm switching pipettes. I pick up a new tip, I'm going into well A9 and I'm going to mix by aspirating up and down a few times and I'm transferring the mix into my thermocycler. I am threshing the tip and I'm placing the pipette where we started.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_transcription = transcribe(audiofile)\n",
    "audio_transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate cost: Images: 0.26775\n",
      "Transcript: 0.001792\n",
      "Output: 0.009\n",
      "Total: 0.278542\n"
     ]
    }
   ],
   "source": [
    "print(f\"Approximate cost: {approx_cost(frames, audio_transcription)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_message(frame):\n",
    "    return {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{frame}\",\n",
    "            \"detail\": \"low\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "PROMPT_MESSAGES = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"The following is the transcribed audio and video frames from a simple lab demonstration.\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"Transcribed audio: {audio_transcription}\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"These are frames from a simple demonstration.\",\n",
    "            },\n",
    "            *map(make_image_message, frames),\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Turn this demonstration into a full laboratory protocol. Format it properly, but be concise.\",\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "# PROMPT_MESSAGES[0][\"content\"].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Pipette Handling and Sample Transfer Protocol\n",
      "\n",
      "Objective: To accurately transfer liquid samples between wells using a pipette in a laboratory setting.\n",
      "\n",
      "Materials:\n",
      "- Micropipettes capable of aspirating 1 µL and 25 µL volumes\n",
      "- Sterile pipette tips for each pipette\n",
      "- 96-well plate\n",
      "- Thermocycler\n",
      "\n",
      "Procedure:\n",
      "\n",
      "1. Pipetting 25 µL:\n",
      "   a. Attach a sterile pipette tip to the micropipette set to 25 µL.\n",
      "   b. Depress the plunger to the first stop.\n",
      "   c. Immerse the pipette tip into the solution in well A1.\n",
      "   d. Slowly release the plunger to aspirate 25 µL of the solution.\n",
      "   e. Move the pipette to well A9, ensuring the tip is above the well's bottom surface.\n",
      "   f. Depress the plunger first to the first stop, then to the second stop to dispense the entire volume into well A9.\n",
      "   g. Eject the used pipette tip into an appropriate waste container.\n",
      "\n",
      "2. Pipetting 1 µL from Well A3:\n",
      "   a. Attach a new sterile pipette tip to the micropipette set to 1 µL.\n",
      "   b. Repeat steps b to g, aspirating from well A3 and dispensing into well A9.\n",
      "\n",
      "3. Pipetting 1 µL from Well A5:\n",
      "   a. Attach a new sterile pipette tip to the micropipette set to 1 µL.\n",
      "   b. Repeat steps b to g, aspirating from well A5 and dispensing into well A9.\n",
      "\n",
      "4. Mixing and Transferring the Mixture to the Thermocycler:\n",
      "   a. Attach a new sterile pipette tip to the micropipette set to 25 µL.\n",
      "   b. Aspirate and dispense the solution in well A9 multiple times to achieve thorough mixing.\n",
      "   c. Transfer the mixed solution to the thermocycler.\n",
      "   d. Eject the used pipette tip into the appropriate waste container.\n",
      "\n",
      "5. Post-Procedure:\n",
      "   a. Dispose of all used pipette tips in a biohazard waste container.\n",
      "   b. Clean pipettes according to the manufacturer's instructions.\n",
      "   c. Return all equipment to its designated storage location.\n",
      "\n",
      "Notes:\n",
      "- Pipette tips should be changed after each sample to prevent cross-contamination.\n",
      "- Ensure pipette calibration is checked regularly to maintain accuracy.\n",
      "- Pipetting technique should be performed with precision to avoid introducing air bubbles or inaccuracies in liquid transfer.\n",
      "\n",
      "Safety Considerations:\n",
      "- Wear appropriate personal protective equipment such as gloves and lab coat.\n",
      "- Handle all biological materials as if they are potentially infectious.\n",
      "- Dispose of waste materials following the laboratory's waste disposal guidelines.\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"model\": \"gpt-4-vision-preview\",\n",
    "    \"messages\": PROMPT_MESSAGES,\n",
    "    \"max_tokens\": 1000,\n",
    "}\n",
    "\n",
    "result = client.chat.completions.create(**params)\n",
    "print(result.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
